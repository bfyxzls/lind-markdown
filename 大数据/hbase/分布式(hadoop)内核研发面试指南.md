# 分布式(hadoop)内核研发面试指南

最近一直在看简历，面试同学，发现符合要求的很少。本文是同学们进入阿里云等公司的hadoop内核研发岗位的一个指引，需要具备哪些要求，如果不具备则可以往这方面努力。

如果 以下的问题不能很好回答，还是多多学习啊。 如果很好回答，对阿里云有兴趣，欢迎找我。

面试：
基础能力
这里涉及一般为

语言基础知识（一般需要在某语言2年以上经验）
比如：JVM的GC算法，JAVA多线程并发机制，线程安全机制，OOM咋办，core了咋办
算法基础知识，冒泡排序、链表、树、线性回归……
分布式理论：数据分布方式、Lease机制、日志技术、两阶段提交、CAP理论、Quorum机制
操作系统
……
复杂工程能力
就是有没有做过，多人协作的项目
你在其中什么角色？ 一般项目有啥难点，遇到难点怎么办？
逻辑思维能力及表达能力
考查思维，思路。需要清楚的回答上述的一些问题，不卑不亢。
潜力
就是发展潜力，如果人比较有冲劲，思维比较活跃，目标明确，对未来规划也比较明确，潜力就比较大
稳定性（我们更加看重持续发展的同学，不是打一枪就跑了）
为什么你要从这家公司离职？
你打算进来，2年后，你想有什么样的改变？
hadoop相关（专家级，一般是开放式的）
比如：

分析时数据倾斜了怎么办？
hdfs写的链路是啥？
集群的利用率不高，为什么？怎么调查？
hbase二级索引是咋回事情？
数据高可靠，服务高可用怎么做？
system占用率比较高，一般啥原因？
如果让你设计一个spark，你打算怎么设计？
流式计算怎么流控？
实时计算与离线怎么混合部署？
一车分布式理论的知识？
笔试：
主要考察编码能力，一般来讲，经常写代码的同学可能比较上手。
一般为5个题目，其中有2个算法题目。笔试过的同学80%都说比较简单，但是做起来就是不太理想。这个要注意平时写代码要记住关键的词（因为写代码没有自动补全，基本就是纸上或者在记事本上写的）

加分项
一直在写技术博客，比如：flink源码分析
参与社区项目开发，比如：贡献spark、hbase源码
发表顶级论文
